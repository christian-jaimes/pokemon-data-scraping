{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Control panel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sDdkWWcB4fVT"
      },
      "outputs": [],
      "source": [
        "project_name = 'Pokemon'\n",
        "file_name = f'{project_name}'\n",
        "\n",
        "# Scrap Scope \n",
        "full_dataset = False\n",
        "part_dataset = 5\n",
        "\n",
        "# Output settings\n",
        "save_dataset_to_csv = True\n",
        "save_dataset_to_json = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Main Script "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nkSwUCXcvJzF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAq2kMxb4qZH",
        "outputId": "8dc09ff8-7fd4-4e47-fcc7-f6082a74d74d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============ Project Pokemon | Script started 2023-09-18 21:04:20 ============\n"
          ]
        }
      ],
      "source": [
        "# Times calculated to have control log of the script\n",
        "start_time = time.time() \n",
        "start_timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
        "print(\"=\"*12,f\"Project {project_name} | Script started {start_timestamp}\",\"=\"*12)\n",
        "\n",
        "# Checks the file directory and creates it dosnt exist\n",
        "file_save_path =\"\\\\\".join(os.getcwd().split('\\\\')[:-1])+\"\\data\"\n",
        "os.makedirs(file_save_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PtLxqMoP5TCY"
      },
      "outputs": [],
      "source": [
        "# Function to output the size of a dataframe\n",
        "def df_size(dataframe_name):\n",
        "  \"\"\"Calculates and formats the size of a dataframe (rows, columns).\"\"\"\n",
        "  rows = dataframe_name.shape[0]\n",
        "  columns = dataframe_name.shape[1]\n",
        "  return f'{rows} rows, {columns} columns.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh1vxZfAG3TN"
      },
      "source": [
        "## Script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pokemon details dataset scarp\n",
        "Calling the full list of pokemons to create a loop, in order to do this I use dict.fromkeys to get rid of duplicates and then make a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Y5Wr4iyC5XP8"
      },
      "outputs": [],
      "source": [
        "pokemon_list = \"https://pokemondb.net/pokedex/all\"\n",
        "\n",
        "# Send request to get the html of each pokemon\n",
        "response = requests.get(pokemon_list)\n",
        "pokemon_soup_list = BeautifulSoup(response.text, \"html.parser\") # Use response.text for decoding\n",
        "\n",
        "pokemon_list = list(dict.fromkeys(pokemon_soup_list.find_all('a', class_=\"ent-name\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List placeholders\n",
        "pokemon_details = []\n",
        "pokemon_evolution = []\n",
        "pokemon_stats = []\n",
        "error_log = []\n",
        "\n",
        "# Calculating data scrap scope (for testing purposes)\n",
        "if full_dataset:\n",
        "  pokemon_scope = len(pokemon_list)\n",
        "else:\n",
        "  pokemon_scope =  part_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "KdPNuT0HdmZz"
      },
      "outputs": [],
      "source": [
        "for index, pokemon in enumerate(pokemon_list[:pokemon_scope], start = 1):\n",
        "  pokemon_url = \"https://pokemondb.net\" + pokemon[\"href\"]\n",
        "\n",
        "  # Send request to get the html of each pokemon\n",
        "  response = requests.get(pokemon_url)\n",
        "  pokemon_soup = BeautifulSoup(response.text, \"html.parser\")  # Use response.text for decoding\n",
        "\n",
        "  ###### Data prep\n",
        "  ### Pokemon Info\n",
        "  pokemon_id = int(pokemon_soup.find(\"th\", string=\"National №\").find_next(\"td\").text)\n",
        "  pokemon_name = pokemon_soup.find(\"h1\").text.strip()\n",
        "  japanese_name = pokemon_soup.find(\"th\", string=\"Japanese\").find_next(\"td\").text.strip()\n",
        "  pokemon_image = pokemon_soup.find(\"div\", class_=\"grid-col\").find(\"img\")['src']\n",
        "  species_data = pokemon_soup.find(\"th\", string=\"Species\").find_next(\"td\").text.strip()\n",
        "  height = pokemon_soup.find(\"th\", string=\"Height\").find_next(\"td\").text.strip()\n",
        "  weight = pokemon_soup.find(\"th\", string=\"Weight\").find_next(\"td\").text.strip()\n",
        "  type_elements = pokemon_soup.find(\"th\", string=\"Type\").find_next(\"td\").find_all(\"a\")\n",
        "  type_info = ', '.join(type_element.text.strip() for type_element in type_elements)\n",
        "  ability_elements = pokemon_soup.find(\"th\", string=\"Abilities\").find_next(\"td\").find_all(\"a\")\n",
        "  abilities = ', '.join(ability_element.text.strip() for ability_element in ability_elements)\n",
        "  ev_yield = pokemon_soup.find(\"th\", string=\"EV yield\").find_next(\"td\").text.strip()\n",
        "  catch_rate = pokemon_soup.find(\"th\", string=\"Catch rate\").find_next(\"td\").text.strip().split()[0]\n",
        "  base_friendship = pokemon_soup.find(\"th\", string=\"Base Exp.\").find_previous(\"td\").text.strip().split()[0]\n",
        "  base_exp = pokemon_soup.find(\"th\", string=\"Base Exp.\").find_next(\"td\").text.strip().split()[0]\n",
        "  growth_rate = pokemon_soup.find(\"th\", string=\"Growth Rate\").find_next(\"td\").text.strip()\n",
        "  gender = pokemon_soup.find(\"th\", string=\"Gender\").find_next(\"td\").text.strip()\n",
        "  generation_title_element = pokemon_soup.find(class_=\"list-nav-title\", string='In other generations')\n",
        "  if generation_title_element: \n",
        "      generation_all = generation_title_element.find_next_siblings('li')\n",
        "      generation = ', '.join(generation_select.text.strip() for generation_select in generation_all)\n",
        "  else:\n",
        "      generation = 9\n",
        "  name_etymology_piece = pokemon_soup.find(\"dl\", class_=\"etymology\").find_all('dt')\n",
        "  name_etymology_desc = pokemon_soup.find(\"dl\", class_=\"etymology\").find_all('dd')\n",
        "  name_etymology = [f\"{dt.text.strip()}: {dd.text.strip()}\" for dt, dd in zip(name_etymology_piece, name_etymology_desc)]\n",
        "  name_etymology = \" | \".join(name_etymology)\n",
        "\n",
        "  ### Pokemon Stats\n",
        "  # HP\n",
        "  hp_elements = pokemon_soup.find(\"th\", string=\"HP\").find_next_siblings(\"td\", class_=\"cell-num\")\n",
        "  hp_stats = [hp_element.text.strip() for hp_element in hp_elements]\n",
        "  base_hp, min_hp, max_hp = hp_stats\n",
        "  # Attack\n",
        "  atk_elements = pokemon_soup.find(\"th\", string=\"Attack\").find_next_siblings(\"td\", class_=\"cell-num\")\n",
        "  atk_stats = [atk_element.text.strip() for atk_element in atk_elements]\n",
        "  base_atk, min_atk, max_atk = atk_stats\n",
        "  # Defense\n",
        "  def_elements = pokemon_soup.find(\"th\", string=\"Defense\").find_next_siblings(\"td\", class_=\"cell-num\")\n",
        "  def_stats = [def_element.text.strip() for def_element in def_elements]\n",
        "  base_def, min_def, max_def = def_stats\n",
        "  # Speed Attack\n",
        "  satk_elements = pokemon_soup.find(\"th\", string=\"Sp. Atk\").find_next_siblings(\"td\", class_=\"cell-num\")\n",
        "  satk_stats = [satk_element.text.strip() for satk_element in satk_elements]\n",
        "  base_satk, min_satk, max_satk = satk_stats\n",
        "  # Speed defense\n",
        "  sdef_elements = pokemon_soup.find(\"th\", string=\"Sp. Def\").find_next_siblings(\"td\", class_=\"cell-num\")\n",
        "  sdef_stats = [sdef_element.text.strip() for sdef_element in sdef_elements]\n",
        "  base_sdef, min_sdef, max_sdef = sdef_stats\n",
        "  # Speed\n",
        "  spd_elements = pokemon_soup.find(\"th\", string=\"Speed\").find_next_siblings(\"td\", class_=\"cell-num\")\n",
        "  spd_stats = [spd_element.text.strip() for spd_element in spd_elements]\n",
        "  base_spd, min_spd, max_spd = spd_stats\n",
        "\n",
        "  pokemon_details.append({\n",
        "                          \"UID\": index,\n",
        "                          \"Pokemon ID\": pokemon_id,\n",
        "                          \"Name\": pokemon_name,\n",
        "                          \"Japanese name\": japanese_name,\n",
        "                          \"Name etymology\":name_etymology,\n",
        "                          \"Image URL\": pokemon_image,\n",
        "                          \"Species\": species_data,\n",
        "                          \"Height\": height,\n",
        "                          \"Weight\": weight,\n",
        "                          \"Type\": type_info,\n",
        "                          \"Abilities\": abilities,\n",
        "                          \"EV Yield\":ev_yield,\n",
        "                          \"catch rate\":catch_rate,\n",
        "                          \"Base Exp\":base_exp,\n",
        "                          \"Growth rate\":growth_rate,\n",
        "                          \"Gender\":gender,\n",
        "                          \"Friendship\":base_friendship,\n",
        "                          \"Generations\":generation\n",
        "                          })\n",
        "\n",
        "  # To add the data to the stats list\n",
        "  pokemon_stats.append({\n",
        "                      \"UID\": index,\n",
        "                      \"Base HP\":base_hp,\n",
        "                      \"Min. HP\":min_hp,\n",
        "                      \"Max. HP\":max_hp,\n",
        "                      \"Base Attack\":base_atk,\n",
        "                      \"Min. Attack\":min_atk,\n",
        "                      \"Max. Attack\":max_atk,\n",
        "                      \"Base Defense\":base_def,\n",
        "                      \"Min. Defense\":min_def,\n",
        "                      \"Max. Defense\":max_def,\n",
        "                      \"Base Spd Attack\":base_satk,\n",
        "                      \"Min. Spd Attack\":min_satk,\n",
        "                      \"Max. Spd Attack\":max_satk,\n",
        "                      \"Base Spd Defense\":base_sdef,\n",
        "                      \"Min. Spd Defense\":min_sdef,\n",
        "                      \"Max. Spd Defense\":max_sdef,\n",
        "                      \"Base Speed\":base_spd,\n",
        "                      \"Min. Speed\":min_spd,\n",
        "                      \"Max. Speed\":max_spd,\n",
        "                      })\n",
        "\n",
        "details_df = pd.DataFrame(pokemon_details)\n",
        "stats_df = pd.DataFrame(pokemon_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pokemon league scrap\n",
        "Getting more data, this to have a dataset that includes all pokemons in their leagues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzulhprAIh88"
      },
      "outputs": [],
      "source": [
        "# Pokedex scrape\n",
        "pokemon_league = []\n",
        "\n",
        "pokedex_url = \"https://pokemondb.net/pokedex\"\n",
        "\n",
        "# Send request and making soup\n",
        "response = requests.get(pokedex_url)\n",
        "pokedex_soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Data find and prep\n",
        "pokedex_panel = pokedex_soup.find('nav', class_='panel panel-nav').find_all('ul')[1]\n",
        "league_name_raw = pokedex_panel.find_all('a')\n",
        "region_name_raw = pokedex_panel.find_all('small', class_='text-muted')\n",
        "league_region_link = [f\"{league.text.strip()}|{region.text.strip()[1:-1]}|{link['href']}\" for league, region, link in zip(league_name_raw, region_name_raw, league_name_raw)][1:]\n",
        "\n",
        "if full_dataset:\n",
        "  league_scope = len(league_region_link)\n",
        "else:\n",
        "  league_scope =  part_dataset\n",
        "\n",
        "for value in league_region_link[:league_scope]:\n",
        "  league_name, league_region, link = value.split(\"|\")\n",
        "  league_link = f'https://pokemondb.net{link}'\n",
        "\n",
        "\n",
        "  response = requests.get(league_link)\n",
        "  league_soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "  # Data call and clean\n",
        "  #### Pokemon names\n",
        "  pokemon_entries = league_soup.find_all(\"div\", class_=\"infocard\")\n",
        "\n",
        "  if full_dataset:\n",
        "    pokemon_entries_scope = len(pokemon_entries)\n",
        "  else:\n",
        "    pokemon_entries_scope =  part_dataset\n",
        "\n",
        "  ## Loop through pokemons in the different leagues\n",
        "  for pokemon in pokemon_entries[:pokemon_entries_scope]:\n",
        "    ##### Data call and clean\n",
        "    # Pokemon info\n",
        "    pokemon_league_number = int(pokemon.find(class_=\"infocard-lg-data text-muted\").find(\"small\").text[1:])\n",
        "    pokemon_name = pokemon.find(\"a\", class_=\"ent-name\").text.strip()\n",
        "    pokemon_link = pokemon.find(class_=\"ent-name\")[\"href\"]\n",
        "    pokemon_sprite = pokemon.find(class_=\"img-fixed\")['src']\n",
        "\n",
        "    # Send request to get the pokemon page html to get the pokemon id.\n",
        "    pokemon_page = \"https://pokemondb.net\" + pokemon_link\n",
        "\n",
        "    page_response = requests.get(pokemon_page)\n",
        "    pokemon_detail_soup = BeautifulSoup(page_response.text, \"html.parser\")\n",
        "\n",
        "    # Data call and clean\n",
        "    pokemon_id = int(pokemon_detail_soup.find(\"th\", string=\"National №\").find_next(\"td\").text)\n",
        "\n",
        "    # To add the data to the pokemon_league list\n",
        "    pokemon_league.append({\n",
        "                            \"League ID\": pokemon_league_number,\n",
        "                            \"Pokemon ID\": pokemon_id,\n",
        "                            \"Sprite URL\": pokemon_sprite,\n",
        "                            \"League name\": league_name,\n",
        "                            \"League Region\": league_region\n",
        "                            })\n",
        "\n",
        "pokemon_league = pd.DataFrame(pokemon_stats)                          "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pokemon league details\n",
        "This piece is with a manual dataset to practice melt and pivot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oQXg8JW_ESCa"
      },
      "outputs": [],
      "source": [
        "region_details = pd.read_csv(fr'{file_save_path}\\pokemon_region_details.csv')\n",
        "\n",
        "region_details = region_details.melt(id_vars=['Type'], var_name='Region', value_name='Values') #columns to rows\n",
        "region_details = region_details.pivot(index='Region', columns='Type', values='Values') # rows to columns\n",
        "region_details = region_details.reset_index() # Reset the index to make 'Region' a column again"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuHTnNPt5gf3"
      },
      "outputs": [],
      "source": [
        "########################################################    Output the data to CSV files    ##########################################################\n",
        "error_log = pd.DataFrame(error_log)\n",
        "\n",
        "\n",
        "#df.to_csv('asdasdasdas.csv', header = True, index = False )\n",
        "\n",
        "if save_dataset_to_csv:\n",
        "  #  Output the full dataset into a csv file\n",
        "  sample_dataset.to_csv(f'{file_name}.csv', header=True, index=False)\n",
        "\n",
        "if save_dataset_to_csv:\n",
        "  print(f\"CSV file saved to {file_name}\")\n",
        "  if save_error_log:\n",
        "    error_log.to_csv(f'{file_name} - error log.csv', header=True, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLUcA_5_537v"
      },
      "outputs": [],
      "source": [
        "########################################################    Output the data to JSON files    ########################################################\n",
        "if save_dataset_to_json:\n",
        "    #  Output the full dataset into a csv file\n",
        "    sample_dataset.to_json(f'{file_name}.json', orient='records', lines=True)\n",
        "\n",
        "if save_dataset_to_json:\n",
        "    print(f\"JSON file saved to {file_name}\")\n",
        "    if save_error_log:\n",
        "        error_log.to_json(f'{file_name} - error log.json', orient='records', lines=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKoZ5e3O57Hv"
      },
      "outputs": [],
      "source": [
        "###################################################################    Metadata    ###################################################################\n",
        "# Record the end time to calculate and format the elapsed time\n",
        "script_end_time = time.time()\n",
        "script_end_timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
        "script_elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(script_end_time - script_start_time))\n",
        "\n",
        "# Time check\n",
        "print(\"=\"*10,f\"{sample_dataset.shape[0]} rows, {sample_dataset.shape[1]} columns in {script_elapsed_time} | Script ended on {script_end_timestamp}\",\"=\"*10,\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhs2I4WW_dMP"
      },
      "outputs": [],
      "source": [
        "print('='*120)\n",
        "print(f'Script finished    |    {sample_dataset.shape[0]}  successful.    |    {sample_dataset.shape[0]}  failed.    |    elapsed time: {script_elapsed_time}')\n",
        "print('='*120)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
